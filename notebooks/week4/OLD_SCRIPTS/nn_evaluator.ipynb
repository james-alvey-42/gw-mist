{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6150c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../mist-base/GW')\n",
    "sys.path.append('../../mist-base/')\n",
    "sys.path.append('../../mist-base/utils')\n",
    "sys.path.append('../../')\n",
    "\n",
    "import gw150814_simulator as gs\n",
    "from src.utils.comb import Comb3, Comb3_Torch, Sim_FD_Additive\n",
    "from gw150814_simulator import GW150814_Additive\n",
    "# import module\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import plotfancy as pf\n",
    "pf.housestyle_rcparams()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from simulators.additive import Simulator_Additive\n",
    "from simulators.utils import *\n",
    "from utils.data import OnTheFlyDataModule, StoredDataModule\n",
    "from utils.module import CustomLossModule_withBounds, BCELossModule\n",
    "\n",
    "mycolors = ['#77aca2', '#ff004f', '#f98e08']\n",
    "# device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad1633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Comb(torch.nn.Module):\n",
    "    def __init__(self, n_bins):\n",
    "        super().__init__()\n",
    "        self.online_norm = OnlineStandardizingLayer((n_bins,), use_average_std=True)\n",
    "        self.net = ResidualNet(1, 1, 128) # 1 input channel, 1 output channel, 128 hidden features\n",
    "        self.logvariance = torch.nn.Parameter(torch.ones(n_bins)*5)\n",
    "\n",
    "    def epsilon(self, x):\n",
    "        x = self.online_norm(x)\n",
    "        x = self.net(x.unsqueeze(1)).squeeze(1)\n",
    "        return x\n",
    "    \n",
    "    def epsilon(self, x):\n",
    "        x = self.online_norm(x)\n",
    "        x = self.net(x.unsqueeze(1)).squeeze(1)\n",
    "        return x\n",
    "    \n",
    "    def snr(self, x):\n",
    "        return self.epsilon(x) / self.logvariance.exp().sqrt()  # [B, N_bins]\n",
    "    \n",
    "    def bounds(self):\n",
    "        return self.logvariance.detach().exp().sqrt().mean(-1) * 5\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        data = x['xi']\n",
    "        # epsilon_real = x['epsilon']\n",
    "        epsilon_sim =  (2 * self.bounds() * torch.rand(x['xi'].shape, device= x['xi'].device, dtype= x['xi'].dtype) - self.bounds()) * x['ni']\n",
    "\n",
    "        epsilon = self.epsilon(data)\n",
    "        mask = ( x['ni'] != 0 )  \n",
    "        squared_error = (epsilon - epsilon_sim)**2                                                                    # [B, N_bins]\n",
    "        l = squared_error / (self.logvariance.exp() + 1e-10) + self.logvariance                     # [B, N_bins]\n",
    "        return (l * mask.float()).sum() * 0.5\n",
    "\n",
    "class Network_SNR(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.online_norm = OnlineStandardizingLayer((Nbins,), use_average_std=True) \n",
    "            self.net = ResidualNet(1, 1, 128)\n",
    "            self.logvariance = torch.nn.Parameter(torch.ones(Nbins)*5)\n",
    "                    \n",
    "        def epsilon(self, x):\n",
    "            x = self.online_norm(x)\n",
    "            x = self.net(x.unsqueeze(1)).squeeze(1)\n",
    "            return x\n",
    "        \n",
    "        def snr(self, x):\n",
    "            return self.epsilon(x) / self.logvariance.exp().sqrt()  # [B, N_bins]\n",
    "        \n",
    "        def bounds(self):\n",
    "            return self.logvariance.detach().exp().sqrt().mean(-1) * 5\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            # Adaptive data generation\n",
    "            ni = x['ni']\n",
    "            epsilon_sim =  (2 * self.bounds() * torch.rand(x['x'].shape, device= x['x'].device, dtype= x['x'].dtype) - self.bounds()) * ni\n",
    "            data =  x['x0'] + epsilon_sim * ni\n",
    "\n",
    "            epsilon = self.epsilon(data)\n",
    "            mask = ( x['ni'] != 0 )  \n",
    "            squared_error = (epsilon - epsilon_sim)**2                                                                    # [B, N_bins]\n",
    "            l = squared_error / (self.logvariance.exp() + 1e-10) + self.logvariance                     # [B, N_bins]\n",
    "            return (l * mask.float()).sum() * 0.5\n",
    "        \n",
    "class Network_epsilon(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.online_norm = OnlineStandardizingLayer((bins,), use_average_std=False) \n",
    "        self.net = UNet1d(1, 1, sizes=(8, 16, 32, 64, 128))\n",
    "        self.logvariance = torch.nn.Parameter(torch.ones(bins)*5)\n",
    "        # self.net = ResidualNet(1, 1, hidden_features=128, num_blocks=2, kernel_size=1, padding=0) \n",
    "\n",
    "    def forward(self, x):\n",
    "        data = x['x']\n",
    "        x = self.net(data.unsqueeze(1)).squeeze(1)\n",
    "        return x\n",
    "                \n",
    "    def epsilon(self, x):\n",
    "        # x = self.online_norm(x)\n",
    "        x = self.net(x.unsqueeze(1)).squeeze(1) # x-net\n",
    "        return x\n",
    "    \n",
    "    def snr(self, x):\n",
    "        return self.epsilon(x) / self.logvariance.exp().sqrt()  # [B, N_bins]\n",
    "    \n",
    "    def bounds(self):\n",
    "        return self.logvariance.detach().exp().sqrt().mean(-1) * 5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adaptive data generation\n",
    "        ni = x['ni']\n",
    "        epsilon_sim =  (2 * self.bounds() * torch.rand(x['x'].shape, device= x['x'].device, dtype= x['x'].dtype) - self.bounds()) * ni\n",
    "        data =  x['x0'] + epsilon_sim * ni\n",
    "        \n",
    "        # data = x['x']\n",
    "        epsilon = self.epsilon(data)\n",
    "        mask = ( x['ni'] != 0 )  \n",
    "        squared_error = (epsilon - epsilon_sim)**2                                                  # [B, N_bins]\n",
    "        l = squared_error / (self.logvariance.exp() + 1e-10) + self.logvariance                     # [B, N_bins]\n",
    "        return (l * mask.float()).sum() * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c422c",
   "metadata": {},
   "source": [
    "## Evaluating The Network\n",
    "\n",
    "First start with a sanity check using some parity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b0d64bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSD distortion mode selected - setting Nbins to 2049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network = torch.load('out/long_uc_model', weights_only=False, map_location=torch.device('cpu'))\n",
    "# network_epsilon = torch.load('out/long_uc_network', weights_only=False,  map_location=torch.device('cpu'))\n",
    "# Nbins = 1000\n",
    "# SIGMA = 1\n",
    "\n",
    "# gen_samples = np.load('FD_samples.npz')\n",
    "# gw150814_post = torch.tensor(gen_samples['waveform'])\n",
    "# gw150814_noise = torch.tensor(gen_samples['noise'])\n",
    "# gw150814_samples = {'mu': gw150814_post, 'noise': gw150814_noise}\n",
    "# simulator = GW150814_Additive(\n",
    "#     gw150814_samples=gw150814_samples, \n",
    "#     bounds=2, \n",
    "#     dtype=torch.float64,\n",
    "#     fraction = 0.5\n",
    "# ) \n",
    "\n",
    "network_epsilon = torch.load('out/test_PSD_c_network', weights_only=False, map_location=torch.device('cpu'))\n",
    "model = torch.load('out/test_PSD_c_model', weights_only=False,  map_location=torch.device('cpu'))\n",
    "a = torch.from_numpy(np.load('base_PSD.npz')['psd'][1])\n",
    "Nbins = len(a)\n",
    "simulator = Sim_FD_Additive(1000, 1,a, bounds=5, white=False)\n",
    "sample = simulator.sample(1)\n",
    "\n",
    "state_dict = network_epsilon.state_dict()\n",
    "new_state_dict = {k.replace('model.', '', 1): v for k, v in state_dict.items()}\n",
    "network_epsilon.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "119e0b25",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 3], expected input[1, 2049, 1] to have 1 channels, but got 2049 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m######### - 2 - ###########\u001b[39;00m\n\u001b[32m     12\u001b[39m ni = torch.eye(Nbins, dtype=obs[\u001b[33m'\u001b[39m\u001b[33mxi\u001b[39m\u001b[33m'\u001b[39m].dtype)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m epsilon_nn_obs = \u001b[43mnetwork_epsilon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta_x\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.detach().cpu().numpy().squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# epsilon_nn_obs = network_epsilon.epsilon(delta_x.to(dtype=torch.float32,device='mps')).detach().cpu().numpy().squeeze(0)\u001b[39;00m\n\u001b[32m     16\u001b[39m variance_nn_obs = network_epsilon.logvariance.exp().detach().cpu().numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mNetwork_epsilon.epsilon\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mepsilon\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# x = self.online_norm(x)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# x-net\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/gw-mist/notebooks/week4/../../mist-base/models/unet_1d.py:115\u001b[39m, in \u001b[36mUNet1d.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     down_outputs = [x]\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m down \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.downs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/gw-mist/notebooks/week4/../../mist-base/models/unet_1d.py:49\u001b[39m, in \u001b[36mDoubleConv1d.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/tgh35/summer25/cam_venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [8, 1, 3], expected input[1, 2049, 1] to have 1 channels, but got 2049 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "######### - 1 - ###########\n",
    "\n",
    "n = 50\n",
    "obs = simulator.sample(1)  \n",
    "# fit = best_fit(obs['xi'][0], simulator)\n",
    "fit = a\n",
    "delta_x = (obs['xi'] - fit).to(dtype=torch.float32)\n",
    "delta_x = delta_x.squeeze(0)\n",
    "\n",
    "######### - 2 - ###########\n",
    "\n",
    "ni = torch.eye(Nbins, dtype=obs['xi'].dtype)\n",
    "\n",
    "epsilon_nn_obs = network_epsilon.epsilon(delta_x.cuda()).detach().cpu().numpy().squeeze(0)\n",
    "# epsilon_nn_obs = network_epsilon.epsilon(delta_x.to(dtype=torch.float32,device='mps')).detach().cpu().numpy().squeeze(0)\n",
    "variance_nn_obs = network_epsilon.logvariance.exp().detach().cpu().numpy()\n",
    "snr_nn_obs = network_epsilon.snr(delta_x.cuda()).detach().cpu().numpy().squeeze(0)\n",
    "# snr_nn_obs = network_epsilon.snr(delta_x.to(dtype=torch.float32,device='mps')).detach().cpu().numpy().squeeze(0)\n",
    "\n",
    "epsilon_obs = get_epsilon(delta_x, ni).squeeze(0)\n",
    "variance_obs = 1 / get_sigma_epsilon_inv2(ni)\n",
    "snr_obs = get_snr(delta_x, ni).squeeze(0)\n",
    "\n",
    "######### - 3 - ###########\n",
    "\n",
    "fig, ax1 = pf.create_plot(size=(4,3))\n",
    "ax2 = fig.add_axes((1.3,0,1,1))\n",
    "ax3 = fig.add_axes((2.6,0,1,1))\n",
    "axs = [ax1,ax2,ax3]\n",
    "\n",
    "axs[0].scatter(x=epsilon_obs, y=epsilon_nn_obs, c='C1', s=30, marker='o',linewidths=0.4, alpha=0.7)\n",
    "axs[1].scatter(x=variance_obs, y=variance_nn_obs, c='C1', s=30, marker='o',linewidths=0.4, alpha=0.7)\n",
    "axs[2].scatter(x=snr_obs, y=snr_nn_obs, c='C1', s=30, marker='o',linewidths=0.4, alpha=0.7)    \n",
    "\n",
    "idx = torch.where(obs['ni']==1)[1]\n",
    "axs[0].scatter(x=epsilon_obs[idx], y=epsilon_nn_obs[idx], c='C0', s=50, marker='x',linewidths=2)\n",
    "axs[1].scatter(x=variance_obs[idx], y=variance_nn_obs[idx], c='C0', s=50, marker='x',linewidths=2)\n",
    "axs[2].scatter(x=snr_obs[idx], y=snr_nn_obs[idx], c='C0', s=50, marker='x',linewidths=2)   \n",
    "\n",
    "\n",
    "axs[0].set_xlabel(r'$\\epsilon$ true')\n",
    "axs[0].set_ylabel(r'$\\epsilon$ NN')\n",
    "axs[1].set_xlabel(r'$\\sigma^2$ true')\n",
    "axs[1].set_ylabel(r'$\\sigma^2$ NN')\n",
    "axs[2].set_xlabel('SNR True')\n",
    "axs[2].set_ylabel('SNR NN')\n",
    "pf.fix_plot(axs)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c5db9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2049])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_x.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c5ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65384c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cam_venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
