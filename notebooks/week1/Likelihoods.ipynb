{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6b400d-2ed1-4a30-a952-cf3444e0efa2",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "This is designed as a codified version of my notes on BI, and to demonstrate some python implementation of different noise models as likelihood functions. Useful references:\n",
    "\n",
    "[GW BI Introduction Paper](https://arxiv.org/pdf/1809.02293)\n",
    "\n",
    "[LIGO Noise Specs (some more good BI here)](https://arxiv.org/pdf/1908.11170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575ccd3-0237-4d4d-98e8-35d17b073d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotfancy as pf\n",
    "import numpy as np\n",
    "pf.housestyle_rcparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96631251-0061-4192-89da-8a6fb04c8fa9",
   "metadata": {},
   "source": [
    "## General Gaussian Case ##\n",
    "\n",
    "In the most general case, we relate our observed data $\\textbf{X}$ from some model prediction $\\boldsymbol{\\mu}(\\boldsymbol{\\theta})$, based on model parameters $\\boldsymbol{\\theta}$ such that\n",
    "\\begin{equation}\n",
    "\\textbf{X} = \\boldsymbol{\\mu}(\\boldsymbol{\\theta}) + \\boldsymbol{\\mathscr{N}}\n",
    "\\end{equation}\n",
    "for some noise vector $\\boldsymbol{\\mathscr{N}}$. The most general Gaussian case models $\\boldsymbol{\\mathscr{N}}$ as a multivariate gaussian - a vector whose elements are correlated, encoded with a covariance matrix, $\\mathscr{C}$, relating the variance of each element\n",
    "\\begin{equation}\n",
    "\\mathscr{C} =\n",
    "\\begin{bmatrix}\n",
    "\\sigma^2(1) & \\sigma(1,2) & ... & \\sigma(1,K) \\\\\n",
    "\\sigma(2,1) & \\sigma^2(2) & ... & \\sigma(2,K) \\\\ \n",
    "... & ... & ... & ... \\\\\n",
    "\\sigma(K,1) & \\sigma(K,2) & ... & \\sigma^2(K)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "for $K = \\texttt{dim}(\\textbf{X})$ and $i,j\\in\\mathbb{Z}^+\\leq K$ for $\\mathscr{C}_{i,j}=\\sigma(i,j)$ covariance. We establish the notation convention here that $\\textbf{X}$, $\\boldsymbol{\\mu}(\\boldsymbol{\\theta})$, and $\\boldsymbol{\\mathscr{N}}$ are *frequency-domain* functions for the data, model and noise hereonwards unless explicitely noted otherwise as time-series.\n",
    "\n",
    "\n",
    "Calculating the likelihood, which by definition follows $\\mathbb{P}(\\textbf{X}|\\boldsymbol{\\mu})$, here is equivalent to some $\\mathbb{P}_{\\boldsymbol{\\mathscr{N}}}(\\textbf{X} - \\boldsymbol{\\mu}(\\boldsymbol{\\theta}))$ conditional probability, which follows from the first equation as our noise distribution;\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(\\textbf{X}|\\boldsymbol{\\mu}) =  \\mathbb{P}_{\\boldsymbol{\\mathscr{N}}}(\\textbf{X} - \\boldsymbol{\\mu}(\\boldsymbol{\\theta})) = \\mathbb{P}_{\\boldsymbol{\\mathscr{N}}}(\\boldsymbol{\\mathscr{N}})\n",
    "\\end{equation}\n",
    "\n",
    "Calculating this in a covariant case is non-trivial - we cannot simply combine probabilities through multiplication - instead we get a multivariate Gaussian of the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}_{MG} = \\frac{1}{[(2\\pi)^K\\textnormal{det}(\\mathscr{C})]^{1/2}} \\exp \\bigg[ -\\frac{1}{2} [\\textbf{X} - \\boldsymbol{\\mu}(\\boldsymbol{\\theta})]^T \\mathscr{C}^{-1} [\\textbf{X} - \\boldsymbol{\\mu}(\\boldsymbol{\\theta})] \\bigg]\n",
    "\\end{equation}\n",
    "\n",
    "We might model this most general case as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f55ddc-f45d-4774-8fc2-24926a85e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global params #\n",
    "fr = 100 # the number of frequency bins we'd have\n",
    "\n",
    "# FIRST FIND COVARIANCE - Observing to create n frequency profiles of the noise #\n",
    "noiseSamples = np.ones([n,fr]) # Dummy array\n",
    "sampleMean = np.average(noiseSamples, axis=0)\n",
    "cen = noiseSamples - sampleMean\n",
    "cov = 1/(fr) * (np.transpose(cen) @ cen)\n",
    "\n",
    "# We might then test this against some data... #\n",
    "\n",
    "data = np.ones([1,fr]) \n",
    "model = np.ones([1,fr]) # Dummy arrays we might observe from an experiment.\n",
    "n = data-model\n",
    "\n",
    "likelihood = 1/(2*np.pi*np.linalg.det(cov))**(fr/2) * np.exp(-0.5*np.transpose(n)@np.linalg.inv(n)@n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860b54e-13be-43c1-a8f8-a3f31ed16c7d",
   "metadata": {},
   "source": [
    "### We can, however, simplify in special cases:\n",
    "\n",
    "The next simplest case is stationary noise; using $N(\\mu,\\sigma^2)$ to represent a normal distribution we express this case as noise following\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mathscr{N}}(t) \\sim\n",
    "\\begin{bmatrix}\n",
    "N(0,\\sigma^2_1) \\\\ N(0,\\sigma^2_2) \\\\ ... \\\\ N(0,\\sigma^2_K)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "After the Fourier transform it follows that this then becomes some complex-valued noise - we make the assumption (easily verifiable by plotting the im-real correlation) that the imaginary and real parts are independently stochastic such that\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mathscr{N}} = \\mathfrak{Re}(\\boldsymbol{\\mathscr{N}}) + i\\mathfrak{Im}(\\boldsymbol{\\mathscr{N}}),\n",
    "\\end{equation}\n",
    "more verbosely that\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mathscr{N}}(f) \\sim\n",
    "\\begin{bmatrix}\n",
    "N(0,\\sigma^2_1) \\\\ N(0,\\sigma^2_2) \\\\ ... \\\\ N(0,\\sigma^2_K)\n",
    "\\end{bmatrix}\n",
    "+ i\n",
    "\\begin{bmatrix}\n",
    "N(0,\\sigma^2_1) \\\\ N(0,\\sigma^2_2) \\\\ ... \\\\ N(0,\\sigma^2_K)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "in the frequency domain. Note that the real and imaginary elements must be thought as independently sampled from their respective distributions $N(0,\\sigma^2_i)$: this is **not** $\\mathscr{N}_i=N(0,\\sigma^2_i)(1+i)$. This distribution has a diagonal covariance matrix and the frequency domain noise transforms to autocorrelated noise with some characteristic $\\textbf{C}(t_i-t_j)$ correlation function in the time domain. We express $\\sigma^2_i = S_n(f_i)$ where $S_n(f_i)$ is the power spectral density at some frequency bin $f_i$, estimated by taking $S_n(f_i) = \\texttt{fft}(\\boldsymbol{\\mathscr{N}}(\\tau))$ where $\\tau$ is some characteristic $t_i\\to t_j$ time period and $\\boldsymbol{\\mathscr{N}}(\\tau)$ is the *time-series* noise. For this simplified covariance matrix \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathscr{C} =\n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_1 & 0 & ... & 0 \\\\\n",
    "0 & \\sigma^2_2 & ... & 0 \\\\ \n",
    "... & ... & ... & ... \\\\ \n",
    "0 & 0 & ... & \\sigma^2_K\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "the determinant of this matrix then follows $\\textnormal{det}(C) = \\prod^K_i \\sigma_i$ and the exponent's argument simplifies to $-\\frac{1}{2}\\sum^K_i [X_i-\\mu(\\boldsymbol{\\theta})_i]/\\sigma^2_i$ giving a simplified likelihood of\n",
    "\\begin{equation}\n",
    "\\mathbb{P}_{\\textnormal{stat}} = \\frac{1}{[\\prod^K_i 2\\pi\\sigma_i]^{1/2}} \\exp \\bigg[ -\\frac{1}{2} \\sum^K_i \\frac{[X-\\mu(\\boldsymbol{\\theta})]^2_i}{\\sigma^2_i} \\bigg]\n",
    "\\end{equation}\n",
    "\n",
    "Given this is now separable we can turn this into a *log likelihood* that follows\n",
    "\\begin{equation}\n",
    "\\log[\\mathbb{P}_{\\textnormal{stat}}(\\textbf{X}|\\boldsymbol{\\theta})] = \\sum^K_i\\bigg[\\frac{1}{2\\pi\\sigma_i} [X-\\mu(\\boldsymbol{\\theta})]^2_i - \\frac{1}{2} \\log[{2\\pi\\sigma_i^2}]\\bigg]\n",
    "\\end{equation}\n",
    "\n",
    "Note that in literature the $\\frac{1}{2} \\log[{2\\pi\\sigma_i^2}]$ term is often omitted as it cancels under addition of likelihoods to create a (log) Bayes factor. With the exception of *glitches*, (short duration transients) and *adiabatic drift* (minute-to-hour drifts in the power spectrum), the noise at LIGO can be approximated as stationary. We might model this case as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a5f59-896c-4733-982c-01fb7ebc34e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf05f5-6f8c-4a2f-bff4-34b0f626f0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
