{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import plotfancy as pf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "pf.housestyle_rcparams()\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('../../mist-base/GW')\n",
    "sys.path.append('../../mist-base/')\n",
    "sys.path.append('../../mist-base/utils')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from src.utils.generators import Simulator_Additive\n",
    "from simulators.utils import *\n",
    "from utils.data import OnTheFlyDataModule, StoredDataModule\n",
    "from utils.module import CustomLossModule_withBounds, BCELossModule\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "\n",
    "mycolors = ['#570f6d', \"#9e8f92\", '#f98e08']\n",
    "folly = '#ff004f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_sigma = 1\n",
    "glob_bkg = True\n",
    "glob_pve_bounds = False\n",
    "glob_det = 'stoch'\n",
    "\n",
    "Nsims = 100_000\n",
    "Nbins = 100\n",
    "train_bounds = 5\n",
    "\n",
    "simulator = Simulator_Additive(Nbins=Nbins, sigma=glob_sigma, bounds=train_bounds, \n",
    "                               fraction=0.2, bkg=glob_bkg, dtype=torch.float64, \n",
    "                               mode='complex', pve_bounds=glob_pve_bounds, bump=glob_det,\n",
    "                               lock_mu=True, lock_sigma=True)     \n",
    "samples = simulator.sample(Nsims=Nsims)  \n",
    "obs = simulator.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554441d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_marker = 'p' if glob_pve_bounds == True else 'n'\n",
    "b_marker = 'b' if glob_bkg == True else 'q'\n",
    "d_marker = 'd' if glob_det == 'det' else 's'\n",
    "# s_marker = '_asymL2'\n",
    "# m_marker = '_m1' # m0 - plain, m1 - learns binwise mu, m2 - learns theta \n",
    "# netid = p_marker+b_marker+d_marker+str(train_bounds)+s_marker+m_marker\n",
    "netid = 'eMu-d_'+p_marker+b_marker+d_marker+str(train_bounds)\n",
    "\n",
    "if not os.path.isdir('figs/'+netid):\n",
    "    os.makedirs('figs/'+netid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = simulator.sample(1)\n",
    "quantiles_long = np.array([7.1508466e-04, 7.9613253e-03, 5.1986761e-02,\n",
    "       2.1462703e-01, 5.8794379e-01, 1.1776060e+00,\n",
    "       1.9190179e+00, 2.7507384e+00, 3.6350725e+00,\n",
    "       4.5491748e+00, 5.4850187e+00], dtype=np.float32)\n",
    "\n",
    "quantiles = np.array([5.1986761e-02,\n",
    "       2.1462703e-01, 5.8794379e-01, 1.1776060e+00,\n",
    "       1.9190179e+00, 2.7507384e+00, 3.6350725e+00], dtype=np.float32)\n",
    "\n",
    "pf.housestyle_rcparams()\n",
    "fig, ax1 = pf.create_plot()\n",
    "\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "ax2 = fig.add_axes((0,-.3,1,0.3), sharex=ax1)\n",
    "ax3 = fig.add_axes((1,-.3,0.2,0.3), sharey=ax2)\n",
    "plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "plt.setp(ax3.get_yticklabels(), visible=False)\n",
    "\n",
    "ax1.plot(test['xi'][0], label=r'$x_i$', color=\"#d931f3\")\n",
    "ax1.plot(test['x0'][0], label=r'$x_0$', color='#ff004f')\n",
    "ax1.plot(test['mu'][0], label=r'$\\mu$', color='black')\n",
    "ax1.set_ylabel(r'$|\\tilde{d}(f)|$')\n",
    "ax1.set_ylim([0,8])\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "\n",
    "resd = test['x0'][0]-test['mu'][0]\n",
    "ax2.plot(resd, color='#ff004f')\n",
    "ax2.set_xlabel(r'$f$')\n",
    "ax2.set_ylabel(r'res ($x_0$)')\n",
    "ax2.set_ylim([0,4.4])\n",
    "grid = torch.linspace(0, 100, 100)\n",
    "for i in range(1,6):\n",
    "    ax1.fill_between(grid, quantiles_long[i]+test['mu'][0], quantiles_long[-i]+test['mu'][0],  color='#b0b0b0', alpha=0.1)\n",
    "    ax2.fill_between(grid, quantiles_long[i], quantiles_long[-i],  color='#b0b0b0', alpha=0.1)\n",
    "    ax3.fill_between(grid, quantiles_long[i], quantiles_long[-i],  color='#b0b0b0', alpha=0.1)\n",
    "\n",
    "ax3.hist(resd, orientation='horizontal', bins=14, edgecolor='black', color='#ff004f', density=True)\n",
    "ax3.set_xlim([0,1])\n",
    "\n",
    "pf.fix_plot([ax1,ax2, ax3])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.online_norm import OnlineStandardizingLayer\n",
    "from models.resnet_1d import ResidualNet\n",
    "\n",
    "class Network_epsilon(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.logvariance = torch.nn.Parameter(torch.ones(Nbins)*5)\n",
    "        self.net = ResidualNet(1, 1, hidden_features=128, num_blocks=2, kernel_size=1, padding=0) \n",
    "\n",
    "        self.mu_predictor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Nbins, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, Nbins)\n",
    "        )\n",
    "    \n",
    "    def mu(self, x):\n",
    "        x = self.mu_predictor(x.unsqueeze(1)).squeeze(1)\n",
    "        return x\n",
    "                \n",
    "    def epsilon(self, x):\n",
    "        resd = x - self.mu(x)\n",
    "        out = self.net(resd.unsqueeze(1)).squeeze(1) # x-net\n",
    "        return out\n",
    "    \n",
    "    def snr(self, x):\n",
    "        return self.epsilon(x) / self.logvariance.exp().sqrt()  # [B, N_bins]\n",
    "    \n",
    "    def bounds(self):\n",
    "        return self.logvariance.detach().exp().sqrt().mean(-1) * 5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adaptive data generation\n",
    "        ni = x['ni']\n",
    "        \n",
    "       # generate a noise block like x #\n",
    "        x_shape = x['x0'].shape # [nsims,nbins]\n",
    "        noise = torch.complex(torch.randn(x_shape).cuda(), torch.randn(x_shape).cuda()).cuda()\n",
    "        norm_noise = torch.abs(noise)\n",
    "\n",
    "        # generate a mu block like x #\n",
    "        m, amp, sigma = [Nbins/2,3,20]\n",
    "        grid = torch.arange(Nbins).cuda()\n",
    "        mu = amp * torch.exp(-0.5 * ((grid - m) / sigma) ** 2)\n",
    "        mu_block = (torch.ones(x_shape).cuda())*mu.unsqueeze(0)\n",
    "\n",
    "        ###########################################\n",
    "        epsilon_sim =  (2 * self.bounds() * torch.rand(x['x'].shape, \n",
    "                                                           device= x['x'].device, \n",
    "                                                           dtype= x['x'].dtype) - self.bounds()) * ni\n",
    "        ###########################################\n",
    "        \n",
    "        # data =  x['x0'] + epsilon_sim * ni\n",
    "\n",
    "        data = norm_noise+mu_block+epsilon_sim\n",
    "        \n",
    "        # net evaluation_m\n",
    "        net_mu = self.mu(data)\n",
    "        error_mu = (net_mu-mu)**2\n",
    "        l_mu = error_mu / (self.logvariance.exp() + 1e-10) + self.logvariance \n",
    "        l_mu_return = l_mu.sum() * 0.5\n",
    "        # net evaluation_e\n",
    "        net_epsilon = self.epsilon(data)\n",
    "        mask = ( x['ni'] != 0 )  \n",
    "        squared_error_e = (net_epsilon - epsilon_sim)**2                                                  # [B, N_bins]\n",
    "        l_e = squared_error_e / (self.logvariance.exp() + 1e-10) + self.logvariance                     # [B, N_bins]\n",
    "        l_e_return = (l_e * mask.float()).sum() * 0.5\n",
    "\n",
    "        return l_mu_return+l_e_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train\n",
    "# def resample(sample):\n",
    "#     sample = simulator._resample(sample)\n",
    "#     sample['x'] = sample['xi']\n",
    "#     # sample = {k: v[0] for k, v in sample.items()}\n",
    "#     return sample\n",
    "\n",
    "batch_size = 124\n",
    "samples = simulator.sample(Nsims=Nsims)  \n",
    "\n",
    "# dm = StoredDataModule(samples, batch_size=batch_size, on_after_load_sample=resample)\n",
    "dm = OnTheFlyDataModule(simulator, Nsims_per_epoch=400*batch_size, batch_size=batch_size, num_workers=31)\n",
    "\n",
    "network_epsilon = Network_epsilon()\n",
    "model = CustomLossModule_withBounds(network_epsilon, learning_rate=3e-3)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", \n",
    "    max_epochs=100, \n",
    "    precision=64,\n",
    "    # fast_dev_run=True\n",
    ")\n",
    "trainer.fit(model, dm)\n",
    "network_epsilon.cuda().eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bed272",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network_epsilon, f'networks/network_{netid}_complex')\n",
    "torch.save(model, f'networks/model_{netid}_complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors to scalars if they are tensors\n",
    "train_loss_history = [loss.item() if hasattr(loss, 'item') else loss for loss in model.train_loss_history]\n",
    "bounds_history = [bound.item() if hasattr(bound, 'item') else bound for bound in model.bounds_history]\n",
    "\n",
    "# Generate a list of epoch numbers\n",
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "# Plot Training Loss over Epochs\n",
    "axs[0].plot(epochs, train_loss_history)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Training Loss')\n",
    "# Plot Bounds over Epochs\n",
    "axs[1].plot(epochs, bounds_history, label='Bounds', color='orange')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Bounds')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figs/{netid}/bounds.png', dpi=300)\n",
    "plt.tight_layout();\n",
    "\n",
    "# Distotions enveloping the data\n",
    "bounds_history = [bound.item() if hasattr(bound, 'item') else bound for bound in model.bounds_history]\n",
    "sample = simulator.sample(1)\n",
    "ni = sample['ni']\n",
    "\n",
    "fig, axs = plt.subplots(4, 5, figsize=(20, (4+1)*3), sharex=True)\n",
    "axs = axs.flatten()\n",
    "for i_b, b in enumerate(bounds_history):\n",
    "    if i_b < len(axs):\n",
    "        axs[i_b].set_title(r\"$b$ = {:.2f}\".format(b))\n",
    "        for j in range(10):\n",
    "            sample = simulator.sample(1)\n",
    "            ni = sample['ni']\n",
    "            # axs[i_b].plot(sample['mu'][0].cpu(), c='k', ls='--')\n",
    "            epsilon_sim =  (2 * b * torch.rand(sample['xi'].shape, device= sample['xi'].device, dtype= sample['xi'].dtype) - b) * ni\n",
    "            data =  sample['x0'] + epsilon_sim * ni\n",
    "            axs[i_b].plot(data[0].cpu(), c='C0', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'figs/{netid}/history.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_epsilon.cuda()\n",
    "N_mc = 2e6\n",
    "\n",
    "ni = torch.eye(Nbins, dtype=obs['xi'].dtype)\n",
    "variance = 1 / get_sigma_epsilon_inv2(ni)\n",
    "\n",
    "batch_size = 2048*2\n",
    "N_batch = int(N_mc / batch_size)\n",
    "\n",
    "ts_bin_H0_epsilon = []\n",
    "for _ in tqdm(range(N_batch)):\n",
    "    mc_samples = simulator.sample(batch_size)\n",
    "    ts_batch =  (network_epsilon.snr(mc_samples['x0'].cuda())**2).detach().cpu().numpy()\n",
    "    ts_bin_H0_epsilon.append(ts_batch)\n",
    "    \n",
    "ts_bin_H0_epsilon = np.concatenate(ts_bin_H0_epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue_grid_eps(dat):\n",
    "    eps_t_mean = np.mean(ts_bin_H0_epsilon, axis=0)\n",
    "    eps_t_ref = ts_bin_H0_epsilon - eps_t_mean\n",
    "    counts = np.sum(eps_t_ref >= dat[:, np.newaxis, :], axis=1)\n",
    "    return (counts + 1) / (len(eps_t_ref) + 1)\n",
    "\n",
    "def pvalue_grid_BCE(dat):\n",
    "    BCE_t_mean = np.mean(ts_bin_H0_BCE, axis=0)\n",
    "    BCE_t_ref = ts_bin_H0_BCE - BCE_t_mean\n",
    "    counts = np.sum(BCE_t_ref >= dat[:, np.newaxis, :], axis=1)\n",
    "    return (counts + 1) / (len(BCE_t_ref) + 1)\n",
    "\n",
    "def chop_middle(array, remove=5, linemode=True):\n",
    "    if len(array)%2==0:\n",
    "        mid_u = int(len(array)/2)\n",
    "        mid_d = mid_u -1\n",
    "        if not linemode:\n",
    "            return np.concatenate([array[:mid_d-remove], array[mid_u+remove:]])\n",
    "        else:\n",
    "            return array[:mid_d-remove] , array[mid_u+remove:], array[mid_u]\n",
    "    else:\n",
    "        mid = len(array)//2\n",
    "        if not linemode:\n",
    "            return np.concatenate([array[:mid-remove], array[mid+remove:]])\n",
    "        else:\n",
    "            return array[:mid-remove], array[mid+remove:], array[mid]\n",
    "        \n",
    "def get_snr2(input:dict):\n",
    "    target = input['x']\n",
    "    snr2_nn = network_epsilon.snr(target.cuda()).detach().cpu().numpy()**2 \n",
    "    return snr2_nn\n",
    "\n",
    "def local_do_ticks(list_of_axes, dir = 'in'):\n",
    "    for ax in list_of_axes:\n",
    "        ax.minorticks_on()\n",
    "        ax.tick_params(top=True,right=True, direction=dir, length=7, which='major')\n",
    "        ax.tick_params(top=True,right=True, direction=dir, length=4, which='minor')\n",
    "\n",
    "def local_fix_frame(ax):\n",
    "    ax.tick_params(color='black', labelcolor='black')\n",
    "    ax.spines[:].set_color('black')\n",
    "    ax.spines[:].set_linewidth(1)\n",
    "    return True\n",
    "\n",
    "def local_fix_plot(a, tickdir ='in'):\n",
    "    for axes in a:\n",
    "        axes.grid(False)\n",
    "        local_do_ticks([axes], tickdir)\n",
    "        local_fix_frame(axes)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SET UP GRID ######\n",
    "positions = torch.arange(0, Nbins, 1).to(dtype=simulator.dtype)\n",
    "amplitudes = torch.linspace(-3, 10, 80).to(dtype=simulator.dtype)\n",
    "\n",
    "position_grid, amplitude_grid = torch.meshgrid(positions,amplitudes)\n",
    "b = {'x':amplitude_grid.T}\n",
    "\n",
    "###### DO BCE STATS ######\n",
    "a = b['x']\n",
    "s = get_snr2(b)\n",
    "dat = [a,s]\n",
    "\n",
    "\n",
    "fig, ax1 = pf.create_plot()\n",
    "ax1.set_xlabel(r'$f$')\n",
    "ax2 = fig.add_axes((1.05, 0,0.1,1))\n",
    "\n",
    "# ax3 = fig.add_axes((0, 1.1,1,1))\n",
    "# plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "# ax4 = fig.add_axes((1.05, 1.1,0.1,1))\n",
    "\n",
    "axs = [ax1,ax2]\n",
    "\n",
    "\n",
    "dat = [pvalue_grid_eps(s)]\n",
    "lab =  [r'$\\mathrm{log}_{10}($p$_{i, \\mathrm{SNR}})$']\n",
    "\n",
    "labcolour = \"#000000\"\n",
    "\n",
    "\n",
    "for q in range(1):\n",
    "    mesh = axs[2*q].pcolormesh(position_grid.T, amplitude_grid.T, np.log10(dat[q]), cmap='magma', vmin=-8)\n",
    "    fig.colorbar(mesh,cax=axs[2*q+1], shrink=0.8, label=lab[q])\n",
    "    axs[2*q+1].set_ylim([-6.5,0])\n",
    "\n",
    "    for j in range(2):\n",
    "        axs[2*q].plot(chop_middle(positions)[j], chop_middle(obs['mu'][0])[j], color=labcolour, linewidth=3)\n",
    "        for i in range(5):\n",
    "            alp = .5+(i/8)\n",
    "            axs[2*q].plot(chop_middle(positions)[j], chop_middle(obs['mu'][0]+quantiles[-i])[j], color=labcolour, alpha=alp)\n",
    "\n",
    "    x = 47\n",
    "    axs[2*q].text(x,obs['mu'][0][int(x)], r'$\\mu$', color=labcolour, size=20)\n",
    "    sigs = [r'$+3\\sigma$',r'$+2\\sigma$',r'$+\\sigma$',r'$\\bar{x}_0$']\n",
    "    x2 = 49\n",
    "    ff = torch.Tensor([0,0,0,-1])\n",
    "    for i in range(1,5):\n",
    "        axs[2*q].text(x2,(obs['mu'][0]+quantiles[-i])[int(x2)], sigs[i-1], color=labcolour, size=12, ha='center')  \n",
    "\n",
    "    axs[2*q].set_ylabel(r'$\\tilde{d}(f)$')\n",
    "\n",
    "local_fix_plot(axs, tickdir='out')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figs/{netid}/pmaps.png', dpi=700, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f201cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_bin/pvaluegrid', dat[0])\n",
    "x_h0_all = np.load('../../data_bin/stats_ref/x_h0_all.npy')\n",
    "\n",
    "kdebloc = np.load('../../data_bin/KDE_ref/KDE_archive.npz')\n",
    "dat_h0 = kdebloc['dat_h0']+1e-21\n",
    "dat_h1 = kdebloc['dat_h1']+1e-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebba4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.linspace(-30, 30, 1000)\n",
    "mask = (matrix >= -2.0) & (matrix <= 4.5)\n",
    "ti = -2 * (np.log(dat_h0)-np.log(dat_h1))\n",
    "t_fn = interp1d(matrix[mask], ti[mask], bounds_error=False, fill_value=40.0)\n",
    "t_samples = t_fn(x_h0_all) \n",
    "\n",
    "x_grid = np.linspace(-2, 8.0, 100)\n",
    "actual_t_values = t_fn(x_grid)\n",
    "num_extreme_vals_mask = t_samples > actual_t_values[:,\n",
    "      np.newaxis]\n",
    "num_extreme_vals = np.sum(num_extreme_vals_mask, axis=1)\n",
    "p_values = num_extreme_vals / len(t_samples)\n",
    "p_values[p_values == 0] = 1e-5\n",
    "\n",
    "fig, ax1 = pf.create_plot(size=(4,1.5))\n",
    "ax2 = fig.add_axes((0,1,1,1), sharex=ax1)\n",
    "ax3 = fig.add_axes((0,2,1,1), sharex=ax1)\n",
    "plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "\n",
    "grid = np.linspace(-30,30, 1000)\n",
    "ti = -2 * (np.log(dat_h0)-np.log(dat_h1))\n",
    "\n",
    "ax1.plot(grid,dat_h0, color='#ff004f', label=r'H$_0$', lw=3)\n",
    "ax1.plot(grid,dat_h1, color='#77aca2', label=r'H$_i$', lw=3)\n",
    "ax1.legend()\n",
    "ax1.set_xlim([-1.5,4.5])\n",
    "ax1.set_xlabel(r'$\\tilde{d}(f)$')\n",
    "ax1.set_ylabel(r'$\\mathbb{P}(\\tilde{d}|...)$')\n",
    "\n",
    "ax2.plot(grid,ti, lw=2,color='black')\n",
    "ax2.set_ylabel(r'$-2\\:\\log\\frac{p(\\tilde{d}|H_0)}{p(\\tilde{d}|H_i)}$')\n",
    "\n",
    "ax3.plot(x_grid, p_values, lw=2, color='black', label='semi-analytical')\n",
    "ax3.set_ylabel(r'p$_i$')\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "grid = np.load('data_bin/pvaluegrid.npy')\n",
    "\n",
    "for i in range(50):\n",
    "      randbin = np.random.randint(0,100)\n",
    "      # randbin=0\n",
    "      randp = grid[:,randbin]\n",
    "      muat = obs['mu'][0][randbin].numpy()\n",
    "      amplitudes = np.linspace(-3, 10, 80)-muat\n",
    "      # ax3.plot(amplitudes, randp, lw=3, color='#598392', label=r'eMu-s'+f', bin {randbin}')\n",
    "      ax3.plot(amplitudes, randp, lw=3, color='#598392', label=r'eMu-s' if i==0 else None, alpha=0.5)\n",
    "\n",
    "ax3.legend(fontsize=12)\n",
    "pf.fix_plot([ax1,ax2,ax3])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figs/pdf2_log.png', dpi=700, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07379039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
